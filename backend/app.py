# backend/app.py
import os
from fastapi import FastAPI, Form, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles

from pydantic import BaseModel
from pathlib import Path
import sys, io, contextlib
import pandas as pd
import shutil

# ====== FastAPI åŸºç¡€ ======
app = FastAPI()

# ====== CORSï¼ˆæŠŠ 127.0.0.1 ä¹Ÿæ”¾è¿›æ¥ï¼‰======
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ====== ç›®å½•å‡†å¤‡ï¼šfinal_result æš´éœ²ä¸ºé™æ€ä¸‹è½½ç›®å½• ======
BASE_DIR = Path(__file__).parent
MODULES_DIR = BASE_DIR / "modules"
FINAL_DIR = MODULES_DIR / "final_result"
FINAL_DIR.mkdir(parents=True, exist_ok=True)
OUT_DIR = MODULES_DIR / "gee_out"
app.mount("/static", StaticFiles(directory=str(FINAL_DIR)), name="static")

# ====== å°† modules åŠ åˆ° PYTHONPATH å¹¶å¯¼å…¥ myMain ======
if str(MODULES_DIR) not in sys.path:
    sys.path.append(str(MODULES_DIR))
from modules.myMain import main as run_pipeline  # ä½ å¤åˆ¶è¿‡æ¥çš„ myMain.main()

# ====== å‰ç«¯åæ ‡æ¨¡å¼çš„è¯·æ±‚ä½“ï¼ˆä½ ä¹‹å‰å†™äº† S2Request ä½†æ²¡å®šä¹‰ï¼‰======
class S2Request(BaseModel):
    minLon: float
    minLat: float
    maxLon: float
    maxLat: float
    startDate: str   # "YYYY-MM-DD"
    endDate: str     # "YYYY-MM-DD"


# ====== å·¥å…·ï¼šè·‘ pipeline å¹¶è¿”å›ç»“æœè·¯å¾„ ======
def _run_and_pick_latest_gpkg(argv_list):
    """
    è¿è¡Œå®Œæ•´ pipelineï¼Œå¹¶è¿”å›åŒ…å« 3 ä¸ªæ–‡ä»¶è·¯å¾„çš„å­—å…¸ï¼š
    merged_gpkg, preview_png, field_summary_xlsx
    """
    sys.argv = ["myMain.py", *argv_list]

    # è¿è¡Œ pipelineï¼ˆæ­¤æ—¶ run_pipeline = myMain.mainï¼‰
    result = run_pipeline()  # ğŸš€ å®ƒä¼šè¿”å›ä¸€ä¸ªå­—å…¸

    # è‹¥ pipeline æ²¡è¿”å›ç»“æœï¼Œåˆ™å…œåº•ä» final_result ä¸­å–æœ€æ–°æ–‡ä»¶
    if not result or not isinstance(result, dict):
        gpkg_list = sorted(FINAL_DIR.glob("merged_*.gpkg"),
                           key=lambda p: p.stat().st_mtime, reverse=True)
        png_list = sorted(FINAL_DIR.glob("preview*.png"),
                            key=lambda p: p.stat().st_mtime, reverse=True)
        xlsx_list = sorted(FINAL_DIR.glob("field_summary_*.xlsx"),
                            key=lambda p: p.stat().st_mtime, reverse=True)

        if not gpkg_list:
            raise RuntimeError("No merged_*.gpkg found under final_result.")
        
        if not png_list:
            raise RuntimeError("No preview*.png found under final_result.")
        
        if not xlsx_list:
            raise RuntimeError("No field_summary_*.xlsx found under final_result.")
        result = {
            "merged_gpkg": gpkg_list[0].name,
            "preview_png": png_list[0].name if png_list else None,
            "field_summary_xlsx": xlsx_list[0].name if xlsx_list else None,
        }
    return result

    # gpkg_list = sorted(FINAL_DIR.glob("merged_*.gpkg"),
    #                        key=lambda p: p.stat().st_mtime, reverse=True)
    # png_list = sorted(FINAL_DIR.glob("preview*.png"),
    #                         key=lambda p: p.stat().st_mtime, reverse=True)
    # xlsx_list = sorted(FINAL_DIR.glob("field_summary_*.xlsx"),
    #                         key=lambda p: p.stat().st_mtime, reverse=True)

    # if not gpkg_list:
    #         raise RuntimeError("No merged_*.gpkg found under final_result.")
        
    # if not png_list:
    #         raise RuntimeError("No preview*.png found under final_result.")
        
    # if not xlsx_list:
    #         raise RuntimeError("No field_summary_*.xlsx found under final_result.")
    # result = {
    #         "merged_gpkg": gpkg_list[0].name,
    #         "preview_png": png_list[0].name if png_list else None,
    #         "field_summary_xlsx": xlsx_list[0].name if xlsx_list else None,
    #     }
    
    # return result

# =========================
# 1) åæ ‡æ¨¡å¼ï¼ˆJSONï¼‰
# =========================
@app.post("/api/s2-process")
async def s2_process(req: S2Request):
    """
    å‰ç«¯ä¼ åæ ‡ + æ—¶é—´ï¼ˆJSONï¼‰ï¼Œè¿è¡Œ myMainï¼Œ
    å¹¶è¿”å›ç”Ÿæˆçš„ gpkg ä¸ png çš„é™æ€è®¿é—® URLã€‚
    """
    try:
        argv = [
            "--mode", "auto",              # ä¸€é”®æµç¨‹
            "--roi_mode", "bbox",          # åæ ‡æ¨¡å¼
            "--gee_bbox", f"{req.minLon},{req.minLat},{req.maxLon},{req.maxLat}",
            "--gee_s2_start", req.startDate,
            "--gee_s2_end", req.endDate,
        ]

        # æ‰§è¡Œå®Œæ•´ pipeline
        result = _run_and_pick_latest_gpkg(argv)

        # ä»è¿”å›çš„ç»“æœå­—å…¸ä¸­å–æ–‡ä»¶å
        gpkg_name = os.path.basename(result["merged_gpkg"])
        png_name = os.path.basename(result["preview_png"])
        xlsx_name = os.path.basename(result["field_summary_xlsx"])
        

        # æ‹¼æˆé™æ€ URL
        base_url = "http://127.0.0.1:5000/static"
        gpkg_url = f"{base_url}/{gpkg_name}"
        preview_url = f"{base_url}/{png_name}"
        xlsx_url = f"{base_url}/{xlsx_name}"

        xlsx_path = FINAL_DIR / xlsx_name

        df = pd.read_excel(xlsx_path)
        top5 = df.head(5).to_dict(orient="records")

        # è¿”å›ç»™å‰ç«¯
        return {
            "status": "done",
            "gpkgUrl": gpkg_url,
            "gpkgName": gpkg_name,
            "previewUrl": preview_url,
            "xlsxUrl": xlsx_url,
            "xlsxName": xlsx_name,
            "top5": top5
        }

    except Exception as e:
        print(f"[ERROR] s2_process failed: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)


@app.post("/api/s2-upload")
async def s2_upload(
    file: UploadFile = File(...),
    startDate: str = Form(...),
    endDate: str = Form(...),
):
    """
    å‰ç«¯ä¸Šä¼  GeoTIFF æ–‡ä»¶ + æ—¶é—´èŒƒå›´ï¼Œåç«¯è¿è¡Œ myMain çš„ tif æ¨¡å¼ã€‚
    """
    try:
        # ä¿å­˜ä¸Šä¼ æ–‡ä»¶åˆ°ä¸´æ—¶è·¯å¾„
        upload_dir = Path(OUT_DIR)
        upload_dir.mkdir(parents=True, exist_ok=True)
        # --- æ–°åå­—ï¼šS2_RGB8 + åŸåç¼€ï¼ˆé»˜è®¤ä¸º .tifï¼‰ ---
        ext = Path(file.filename).suffix or ".tif"
        new_filename = f"S2_RGB8{ext}"
        tif_path = upload_dir / new_filename
        # === çœŸçš„æŠŠä¸Šä¼ çš„å†…å®¹å†™å…¥ç£ç›˜ï¼ˆWindows/mac éƒ½ä¸€æ ·ï¼‰===

        try:
            file.file.seek(0)  # ä¿é™©ï¼šå…‰æ ‡å¤ä½
        except Exception:
            pass
        with open(tif_path, "wb") as f:
            shutil.copyfileobj(file.file, f)
        print(f"[SAVE] wrote tif to: {tif_path} | exists={tif_path.exists()}")
        # ===============================================
        # ç›®æ ‡æ˜¯ï¼štif_path ç›¸å¯¹äº backend/modules/
        tif_abs = tif_path.resolve()
        modules_dir = Path(__file__).resolve().parent / "modules"
        relative_tif = tif_abs.relative_to(modules_dir) if tif_abs.is_relative_to(modules_dir) else tif_abs
        print(f"[UPLOAD] Received file: {tif_path}")

        # === æ–°å¢ï¼šæ„é€ å¯¹ç®¡çº¿ç¨³å®šçš„ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹ backend æ ¹ï¼‰ï¼Œå¹¶ç»Ÿä¸€æ–œæ  ===
        # å¦‚æœ relative_tif å½¢å¦‚ "final_result/xxx.tif"ï¼Œå‰é¢è¡¥ä¸Š "modules/"
        rel_for_pipeline = (
            ("modules" / relative_tif) if isinstance(relative_tif, Path) else Path("modules") / relative_tif
        ).as_posix() if not str(relative_tif).startswith(("modules/", "modules\\")) else Path(str(relative_tif)).as_posix()

        argv = [
            "--mode", "auto",
            "--roi_mode", "tif",
            "--user_tif", f"./{rel_for_pipeline}",
            "--gee_s2_start", startDate,
            "--gee_s2_end", endDate,
        ]

        print("--gee_s2_start:" + startDate)
        print("--gee_s2_end:" + endDate)

        print("--user_tif:" + f"./{rel_for_pipeline}")

        print(argv)

         # === æ–°å¢ï¼šåœ¨ backend ç›®å½•ä¸‹è¿è¡Œï¼Œä¿è¯ç›¸å¯¹è·¯å¾„æ­£ç¡® ===
        _backend_dir = Path(__file__).resolve().parent
        _old_cwd = Path.cwd()
        try:
            os.chdir(_backend_dir)
            # è°ƒç”¨ pipelineï¼ˆmyMain.mainï¼‰
            result = _run_and_pick_latest_gpkg(argv)
        finally:
            os.chdir(_old_cwd)

        # æ‹¿å‡ºç»“æœæ–‡ä»¶å
        gpkg_name = result["merged_gpkg"]
        png_name = result["preview_png"]
        xlsx_name = result["field_summary_xlsx"]
        xlsx_path = FINAL_DIR / xlsx_name

        # æ‹¼æˆ URL
        base_url = "http://127.0.0.1:5000/static"
        gpkg_url = f"{base_url}/{gpkg_name}"
        preview_url = f"{base_url}/{png_name}"
        xlsx_url = f"{base_url}/{xlsx_name}"

        # è¯»å‡ºå‰äº”è¡Œç»Ÿè®¡
        df = pd.read_excel(xlsx_path)
        top5 = df.head(5).to_dict(orient="records")
        if tif_path.exists():
            tif_path.unlink()
            print(f"[CLEAN] Deleted uploaded file: {tif_path}")

        return {
            "status": "done",
            "previewUrl": preview_url,
            "gpkgUrl": gpkg_url,
            "gpkgName": gpkg_name,
            "xlsxUrl": xlsx_url,
            "xlsxName": xlsx_name,
            "top5": top5,
        }

    except Exception as e:
        print(f"[ERROR] s2_upload failed: {e}")
        return JSONResponse({"error": str(e)}, status_code=500)